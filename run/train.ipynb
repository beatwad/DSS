{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import yaml\n",
    "import torch\n",
    "from omegaconf import DictConfig\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import (\n",
    "    LearningRateMonitor,\n",
    "    ModelCheckpoint,\n",
    "    RichModelSummary,\n",
    "    RichProgressBar,\n",
    ")\n",
    "\n",
    "from src.datamodule import SleepDataModule\n",
    "# from src.modelmodule.seg import class SegValidDataset(Dataset):\n",
    "\n",
    "\n",
    "\n",
    "# def main(cfg: dict):  # type: ignore\n",
    "#     seed_everything(cfg.seed)\n",
    "\n",
    "#     # init lightning model\n",
    "#     datamodule = SegDataModule(cfg)\n",
    "#     # LOGGER.info(\"Set Up DataModule\")\n",
    "#     model = SegModel(\n",
    "#         cfg, datamodule.valid_event_df, len(cfg.features), len(cfg.labels), cfg.duration\n",
    "#     )\n",
    "\n",
    "#     # set callbacks\n",
    "#     checkpoint_cb = ModelCheckpoint(\n",
    "#         verbose=True,\n",
    "#         monitor=cfg.monitor,\n",
    "#         mode=cfg.monitor_mode,\n",
    "#         save_top_k=1,\n",
    "#         save_last=False,\n",
    "#     )\n",
    "#     lr_monitor = LearningRateMonitor(\"epoch\")\n",
    "#     progress_bar = RichProgressBar()\n",
    "#     model_summary = RichModelSummary(max_depth=2)\n",
    "\n",
    "#     trainer = Trainer(\n",
    "#         # env\n",
    "#         default_root_dir=Path.cwd(),\n",
    "#         # num_nodes=cfg.training.num_gpus,\n",
    "#         accelerator=cfg.accelerator,\n",
    "#         precision=16 if cfg.use_amp else 32,\n",
    "#         # training\n",
    "#         fast_dev_run=cfg.debug,  # run only 1 train batch and 1 val batch\n",
    "#         max_epochs=cfg.epoch,\n",
    "#         max_steps=cfg.epoch * len(datamodule.train_dataloader()),\n",
    "#         gradient_clip_val=cfg.gradient_clip_val,\n",
    "#         accumulate_grad_batches=cfg.accumulate_grad_batches,\n",
    "#         callbacks=[checkpoint_cb, lr_monitor, progress_bar, model_summary],\n",
    "#         logger=None,\n",
    "#         # resume_from_checkpoint=resume_from,\n",
    "#         num_sanity_val_steps=0,\n",
    "#         log_every_n_steps=int(len(datamodule.train_dataloader()) * 0.1),\n",
    "#         sync_batchnorm=True,\n",
    "#         check_val_every_n_epoch=cfg.check_val_every_n_epoch,\n",
    "#     )\n",
    "\n",
    "#     trainer.fit(model, datamodule=datamodule)\n",
    "\n",
    "#     # load best weights\n",
    "#     model = model.load_from_checkpoint(\n",
    "#         checkpoint_cb.best_model_path,\n",
    "#         cfg=cfg,\n",
    "#         val_event_df=datamodule.valid_event_df,\n",
    "#         feature_dim=len(cfg.features),\n",
    "#         num_classes=len(cfg.labels),\n",
    "#         duration=cfg.duration,\n",
    "#     )\n",
    "#     weights_path = str(\"model_weights.pth\")  # type: ignore\n",
    "\n",
    "#     torch.save(model.model.state_dict(), weights_path)\n",
    "\n",
    "#     return\n",
    "\n",
    "cfg = yaml.safe_load(Path('conf/train.yaml').read_text())\n",
    "cfg_dir = yaml.safe_load(Path('conf/dir/local.yaml').read_text())\n",
    "cfg_split = yaml.safe_load(Path('conf/split/fold_0.yaml').read_text())\n",
    "cfg_model = yaml.safe_load(Path('conf/model/Spec2DCNN.yaml').read_text())\n",
    "cfg_fe = yaml.safe_load(Path('conf/feature_extractor/CNNSpectrogram.yaml').read_text())\n",
    "cfg_de = yaml.safe_load(Path('conf/decoder/UNet1DDecoder.yaml').read_text())\n",
    "cfg_ds = yaml.safe_load(Path('conf/dataset/seg.yaml').read_text())\n",
    "\n",
    "cfg['dir'] = cfg_dir\n",
    "cfg['split'] = cfg_split\n",
    "cfg['model'] = cfg_model\n",
    "cfg['feature_extractor'] = cfg_fe\n",
    "cfg['decoder'] = cfg_de\n",
    "cfg['dataset'] = cfg_ds\n",
    "\n",
    "cfg = DictConfig(cfg)\n",
    "\n",
    "# main(cfg)\n",
    "\n",
    "datamodule = SleepDataModule(cfg)\n",
    "\n",
    "x = datamodule.val_dataloader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = None\n",
    "\n",
    "for i in x:\n",
    "    l = i['label']\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(idx+length//2, y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (30,) into shape (25,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/alex/Kaggle/DSS/run/train.ipynb Cell 4\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alex/Kaggle/DSS/run/train.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m idx \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alex/Kaggle/DSS/run/train.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m length \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(length, \u001b[39mmin\u001b[39m(idx\u001b[39m+\u001b[39mlength\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m,y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) \u001b[39m-\u001b[39m \u001b[39mmax\u001b[39m(idx\u001b[39m-\u001b[39mlength\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m,\u001b[39m0\u001b[39m))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/alex/Kaggle/DSS/run/train.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m y[\u001b[39mmax\u001b[39;49m(idx\u001b[39m-\u001b[39;49mlength\u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m2\u001b[39;49m, \u001b[39m0\u001b[39;49m):\u001b[39mmin\u001b[39;49m(idx\u001b[39m+\u001b[39;49mlength\u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m2\u001b[39;49m, y\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m])] \u001b[39m=\u001b[39m gaussian_kernel(length, sigma\u001b[39m=\u001b[39mlength\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m4\u001b[39m)[:length]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alex/Kaggle/DSS/run/train.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m plt\u001b[39m.\u001b[39mplot(y)\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (30,) into shape (25,)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "length = 40\n",
    "y = l[0,:,0].numpy()\n",
    "idx = 10\n",
    "\n",
    "length = min(length, min(idx+length//2,y.shape[0]) - max(idx-length//2,0))\n",
    "y[max(idx-length//2, 0):min(idx+length//2, y.shape[0])] = gaussian_kernel(length, sigma=length//4)[:length]\n",
    "plt.plot(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
