{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>event</th>\n",
       "      <th>series_id</th>\n",
       "      <th>night</th>\n",
       "      <th>onset</th>\n",
       "      <th>wakeup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>29d3469bd15d</td>\n",
       "      <td>1</td>\n",
       "      <td>3960.0</td>\n",
       "      <td>10164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>29d3469bd15d</td>\n",
       "      <td>2</td>\n",
       "      <td>21996.0</td>\n",
       "      <td>27132.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>29d3469bd15d</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>29d3469bd15d</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>29d3469bd15d</td>\n",
       "      <td>5</td>\n",
       "      <td>73212.0</td>\n",
       "      <td>79368.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>29d3469bd15d</td>\n",
       "      <td>6</td>\n",
       "      <td>90672.0</td>\n",
       "      <td>96612.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>29d3469bd15d</td>\n",
       "      <td>7</td>\n",
       "      <td>107820.0</td>\n",
       "      <td>113712.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>29d3469bd15d</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>29d3469bd15d</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>29d3469bd15d</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>29d3469bd15d</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>29d3469bd15d</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>29d3469bd15d</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>29d3469bd15d</td>\n",
       "      <td>14</td>\n",
       "      <td>229224.0</td>\n",
       "      <td>235152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>29d3469bd15d</td>\n",
       "      <td>15</td>\n",
       "      <td>246576.0</td>\n",
       "      <td>252852.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>29d3469bd15d</td>\n",
       "      <td>16</td>\n",
       "      <td>264456.0</td>\n",
       "      <td>271212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>29d3469bd15d</td>\n",
       "      <td>17</td>\n",
       "      <td>281412.0</td>\n",
       "      <td>286872.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>29d3469bd15d</td>\n",
       "      <td>18</td>\n",
       "      <td>298212.0</td>\n",
       "      <td>304056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>29d3469bd15d</td>\n",
       "      <td>19</td>\n",
       "      <td>315444.0</td>\n",
       "      <td>321156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>29d3469bd15d</td>\n",
       "      <td>20</td>\n",
       "      <td>332676.0</td>\n",
       "      <td>338436.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>29d3469bd15d</td>\n",
       "      <td>21</td>\n",
       "      <td>350232.0</td>\n",
       "      <td>355944.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>29d3469bd15d</td>\n",
       "      <td>22</td>\n",
       "      <td>367020.0</td>\n",
       "      <td>373404.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>29d3469bd15d</td>\n",
       "      <td>23</td>\n",
       "      <td>384372.0</td>\n",
       "      <td>390852.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "event     series_id  night     onset    wakeup\n",
       "1250   29d3469bd15d      1    3960.0   10164.0\n",
       "1251   29d3469bd15d      2   21996.0   27132.0\n",
       "1252   29d3469bd15d      3       NaN       NaN\n",
       "1253   29d3469bd15d      4       NaN       NaN\n",
       "1254   29d3469bd15d      5   73212.0   79368.0\n",
       "1255   29d3469bd15d      6   90672.0   96612.0\n",
       "1256   29d3469bd15d      7  107820.0  113712.0\n",
       "1257   29d3469bd15d      8       NaN       NaN\n",
       "1258   29d3469bd15d      9       NaN       NaN\n",
       "1259   29d3469bd15d     10       NaN       NaN\n",
       "1260   29d3469bd15d     11       NaN       NaN\n",
       "1261   29d3469bd15d     12       NaN       NaN\n",
       "1262   29d3469bd15d     13       NaN       NaN\n",
       "1263   29d3469bd15d     14  229224.0  235152.0\n",
       "1264   29d3469bd15d     15  246576.0  252852.0\n",
       "1265   29d3469bd15d     16  264456.0  271212.0\n",
       "1266   29d3469bd15d     17  281412.0  286872.0\n",
       "1267   29d3469bd15d     18  298212.0  304056.0\n",
       "1268   29d3469bd15d     19  315444.0  321156.0\n",
       "1269   29d3469bd15d     20  332676.0  338436.0\n",
       "1270   29d3469bd15d     21  350232.0  355944.0\n",
       "1271   29d3469bd15d     22  367020.0  373404.0\n",
       "1272   29d3469bd15d     23  384372.0  390852.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event_df = pd.read_csv(\"../data/child-mind-institute-detect-sleep-states/train_events.csv\")\n",
    "\n",
    "event_df = (\n",
    "    event_df.pivot(index=[\"series_id\", \"night\"], columns=\"event\", values=\"step\")\n",
    "    # .dropna()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "event_df[event_df[\"series_id\"] == \"29d3469bd15d\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas\n",
    "\n",
    "- try ensemble of all folds with cutmix \n",
    "- check fixed sampling \n",
    "\n",
    "- try with full data\n",
    "- try with 6, 7, 8 folds\n",
    "\n",
    "- try again gaussian loss\n",
    "- fix DETR\n",
    "\n",
    "What works and gives boost but overfits:\n",
    "- LSTM encoder (0.772/~0.722)\n",
    "- resnet50 (0.780/0.722)\n",
    "- duration 17280 (0.772/0.722)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1800226/4092731947.py:40: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  initialize(config_path=config_path.as_posix())\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from hydra import initialize, compose\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from src.utils.metrics import event_detection_ap\n",
    "\n",
    "from src.utils.post_process import post_process_for_seg\n",
    "import jupyter_black\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "\n",
    "\n",
    "jupyter_black.load()\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "INFERENCE = True\n",
    "EXP_NAME = \"transformer_dur_8640_folds\"\n",
    "RUN_NAME = \"run0\"\n",
    "TYPE = \"score\"\n",
    "\n",
    "if INFERENCE:\n",
    "    RESULT_DIR = Path(\"../output/inference\") / EXP_NAME  # / RUN_NAME\n",
    "    hydra_result_dir = Path(\"../output/train\") / \"transformer_dur_8640_folds\" / RUN_NAME\n",
    "else:\n",
    "    RESULT_DIR = Path(\"../output/train\") / EXP_NAME / RUN_NAME\n",
    "    hydra_result_dir = Path(\"../output/train\") / EXP_NAME / RUN_NAME\n",
    "\n",
    "\n",
    "def load_config(result_dir: Path):\n",
    "    # clear previous initialization\n",
    "    GlobalHydra.instance().clear()\n",
    "\n",
    "    # initialize hydra\n",
    "    config_path = result_dir / \".hydra\"\n",
    "    initialize(config_path=config_path.as_posix())\n",
    "    # load the config\n",
    "    cfg = compose(config_name=\"config\")\n",
    "\n",
    "    return cfg\n",
    "\n",
    "\n",
    "cfg = load_config(hydra_result_dir)\n",
    "\n",
    "if INFERENCE:\n",
    "    preds = np.load(RESULT_DIR / f\"preds.npy\")\n",
    "    keys = np.load(RESULT_DIR / f\"keys.npy\")\n",
    "else:\n",
    "    preds = np.load(RESULT_DIR / f\"preds_{TYPE}.npy\")\n",
    "    labels = np.load(RESULT_DIR / f\"labels_{TYPE}.npy\")\n",
    "    keys = np.load(RESULT_DIR / \"keys.npy\")\n",
    "\n",
    "gt_df = pd.read_csv(Path(cfg.dir.data_dir) / \"train_events.csv\")\n",
    "gt_df = gt_df[gt_df[\"series_id\"].isin(cfg.split.valid_series_ids)].dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize postprocess parameters using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7945928237902742, 352926)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(Path(cfg.dir.processed_dir) / \"train\" / \"series_lens.json\") as f:\n",
    "    series_lens = json.load(f)\n",
    "\n",
    "pred_df = post_process_for_seg(keys, preds, series_lens, score_th=0.0001, distance=70, offset=8)\n",
    "# pred_df = pred_df.to_pandas()\n",
    "\n",
    "score = event_detection_ap(gt_df, pred_df)\n",
    "\n",
    "score, len(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (0.7945928237902742, 352926)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold 5_0 - 0.765 / 0.733 - rank 1\n",
    "# fold 5_3 - 0.772 / 0.733 - rank 3\n",
    "\n",
    "# fold 10_2 - 0.0001 / 85 / 0.811 / 0.729 (0.709 for the best loss) - rank 6\n",
    "# fold 10_4 - 0.0001 / 70 / 0.789 / 0.734 - rank 2\n",
    "# fold 10_6 - 0.0001 / 70 / 0.779 / 0.733 - rank 4\n",
    "# fold 10_7 - 0.0001 / 80 / 0.792 / 0.729 - rank 5\n",
    "# fold 10_9 - 0.0001 / 80 / 0.812 / 0.722"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial):\n",
    "    # score_th = 0.005\n",
    "    score_th = trial.suggest_float(\"score_th\", 0, 0.5)\n",
    "    distance = trial.suggest_int(\"distance\", 30, 400)\n",
    "\n",
    "    pred_df: pl.DataFrame = post_process_for_seg(keys, preds, score_th=score_th, distance=distance)\n",
    "    score = event_detection_ap(gt_df, pred_df)\n",
    "\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_sample(gt_df, keys, preds, labels, num_samples=1, num_chunks=10):\n",
    "    # get series ids\n",
    "    series_ids = np.array(list(map(lambda x: x.split(\"_\")[0], keys)))\n",
    "    unique_series_ids = np.unique(series_ids)\n",
    "\n",
    "    # get random series\n",
    "    random_series_ids = np.random.choice(unique_series_ids, num_samples)\n",
    "\n",
    "    for i, random_series_id in enumerate(random_series_ids):\n",
    "        # get random series\n",
    "        series_idx = np.where(series_ids == random_series_id)[0]\n",
    "        this_series_preds = preds[series_idx].reshape(-1, 3)\n",
    "        this_series_labels = labels[series_idx].reshape(-1, 3)\n",
    "\n",
    "        # split series\n",
    "        this_series_preds = np.split(this_series_preds, num_chunks)\n",
    "        this_series_labels = np.split(this_series_labels, num_chunks)\n",
    "        this_series_len = [0] + [len(x) for x in this_series_labels]\n",
    "        this_series_len = np.cumsum(this_series_len)\n",
    "\n",
    "        gt_df = gt_df[gt_df[\"series_id\"] == random_series_id]\n",
    "\n",
    "        fig, axs = plt.subplots(num_chunks, 1, figsize=(20, 5 * num_chunks))\n",
    "\n",
    "        if num_chunks == 1:\n",
    "            axs = [axs]\n",
    "\n",
    "        for j in range(num_chunks):\n",
    "            this_series_preds_chunk = this_series_preds[j]\n",
    "            this_series_labels_chunk = this_series_labels[j]\n",
    "\n",
    "            # get onset and wakeup idx\n",
    "            gt_tmp = gt_df[\n",
    "                (gt_df[\"step\"] >= this_series_len[j]) & (gt_df[\"step\"] <= this_series_len[j + 1])\n",
    "            ]\n",
    "            onset_idx = gt_tmp.loc[gt_tmp[\"event\"] == \"onset\", \"step\"].to_list()\n",
    "            onset_idx = onset_idx - this_series_len[j]\n",
    "            wakeup_idx = gt_tmp.loc[gt_tmp[\"event\"] == \"wakeup\", \"step\"].to_list()\n",
    "            wakeup_idx = wakeup_idx - this_series_len[j]\n",
    "\n",
    "            axs[j].plot(this_series_preds_chunk[:, 0], label=\"pred_sleep\")\n",
    "            axs[j].plot(this_series_preds_chunk[:, 1], label=\"pred_onset\")\n",
    "            axs[j].plot(this_series_preds_chunk[:, 2], label=\"pred_wakeup\")\n",
    "            axs[j].vlines(onset_idx, 0, 1, label=\"onset\", linestyles=\"dashed\", color=\"C1\")\n",
    "            axs[j].vlines(wakeup_idx, 0, 1, label=\"wakeup\", linestyles=\"dashed\", color=\"C2\")\n",
    "            axs[j].set_ylim(0, 1)\n",
    "            axs[j].set_title(f\"series_id: {random_series_id} chunk_id: {j}\")\n",
    "            axs[j].legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\", borderaxespad=0)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "plot_random_sample(gt_df, keys, preds, labels, num_chunks=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "BEST_MODEL = \"ensemble\"\n",
    "FOLD = 0\n",
    "\n",
    "DURATION = 8640\n",
    "DOWNSAMPLE_RATE = 2\n",
    "PHASE = \"train\"\n",
    "EXP_NAME = \"transformer_best_folds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "[5.0GB(+3.9GB):2.2sec] load test dataloader \n",
      "List of models: ['/home/alex/Kaggle/DSS/output/train/transformer_best_folds/fold_0.pth', '/home/alex/Kaggle/DSS/output/train/transformer_best_folds/fold_10_2.pth', '/home/alex/Kaggle/DSS/output/train/transformer_best_folds/fold_10_4.pth', '/home/alex/Kaggle/DSS/output/train/transformer_best_folds/fold_3.pth']\n",
      "load weight from /home/alex/Kaggle/DSS/output/train/transformer_best_folds/fold_0.pth\n",
      "load weight from /home/alex/Kaggle/DSS/output/train/transformer_best_folds/fold_10_2.pth\n",
      "load weight from /home/alex/Kaggle/DSS/output/train/transformer_best_folds/fold_10_4.pth\n",
      "load weight from /home/alex/Kaggle/DSS/output/train/transformer_best_folds/fold_3.pth\n",
      "[5.7GB(+0.7GB):4.8sec] load model \n",
      "inference: 100%|████████████████████████████| 1867/1867 [02:38<00:00, 11.80it/s]\n",
      "[7.4GB(+1.7GB):177.8sec] inference \n",
      "inference: 100%|████████████████████████████| 1867/1867 [02:38<00:00, 11.77it/s]\n",
      "[7.4GB(+0.0GB):180.0sec] inference \n",
      "inference: 100%|████████████████████████████| 1867/1867 [02:36<00:00, 11.93it/s]\n",
      "[7.4GB(+0.0GB):176.6sec] inference \n",
      "inference: 100%|████████████████████████████| 1867/1867 [02:36<00:00, 11.89it/s]\n",
      "[7.4GB(+0.0GB):176.8sec] inference \n",
      "[7.4GB(+0.0GB):1.0sec] make submission \n"
     ]
    }
   ],
   "source": [
    "!python -m run.inference\\\n",
    "    dir=local\\\n",
    "    model.params.encoder_name=resnet34\\\n",
    "    model.params.encoder_weights=null\\\n",
    "    num_workers=12\\\n",
    "    exp_name=$EXP_NAME\\\n",
    "    weight.run_name=single\\\n",
    "    batch_size=8\\\n",
    "    duration=$DURATION\\\n",
    "    downsample_rate=$DOWNSAMPLE_RATE\\\n",
    "    pp.score_th=0.0015\\\n",
    "    pp.distance=70\\\n",
    "    phase=$PHASE\\\n",
    "    best_model=$BEST_MODEL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
