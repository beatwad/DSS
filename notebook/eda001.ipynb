{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event</th>\n",
       "      <th>onset</th>\n",
       "      <th>wakeup</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>series_id</th>\n",
       "      <th>night</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">038441c925bb</th>\n",
       "      <th>1</th>\n",
       "      <td>4992.0</td>\n",
       "      <td>10932.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20244.0</td>\n",
       "      <td>27492.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39996.0</td>\n",
       "      <td>44400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57240.0</td>\n",
       "      <td>62856.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>91296.0</td>\n",
       "      <td>97860.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">fe90110788d2</th>\n",
       "      <th>30</th>\n",
       "      <td>505116.0</td>\n",
       "      <td>511284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>522852.0</td>\n",
       "      <td>529104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>538956.0</td>\n",
       "      <td>547152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>556560.0</td>\n",
       "      <td>560604.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>574620.0</td>\n",
       "      <td>581604.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4790 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "event                  onset    wakeup\n",
       "series_id    night                    \n",
       "038441c925bb 1        4992.0   10932.0\n",
       "             2       20244.0   27492.0\n",
       "             3       39996.0   44400.0\n",
       "             4       57240.0   62856.0\n",
       "             6       91296.0   97860.0\n",
       "...                      ...       ...\n",
       "fe90110788d2 30     505116.0  511284.0\n",
       "             31     522852.0  529104.0\n",
       "             32     538956.0  547152.0\n",
       "             33     556560.0  560604.0\n",
       "             34     574620.0  581604.0\n",
       "\n",
       "[4790 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms.functional import resize\n",
    "\n",
    "from src.conf import InferenceConfig, TrainConfig\n",
    "from src.utils.common import (gaussian_label, nearest_valid_size,\n",
    "                              negative_sampling, pad_if_needed, random_crop)\n",
    "\n",
    "\n",
    "###################\n",
    "# Label\n",
    "###################\n",
    "def get_seg_label(\n",
    "    this_event_df: pd.DataFrame, num_frames: int, duration: int, start: int, end: int\n",
    ") -> np.ndarray:\n",
    "    # # (start, end)の範囲と(onset, wakeup)の範囲が重なるものを取得\n",
    "    this_event_df = this_event_df.query(\"@start <= wakeup & onset <= @end\")\n",
    "\n",
    "    label = np.zeros((num_frames, 3))\n",
    "    # onset, wakeup, sleepのラベルを作成\n",
    "    for onset, wakeup in this_event_df[[\"onset\", \"wakeup\"]].to_numpy():\n",
    "        onset = int((onset - start) / duration * num_frames)\n",
    "        wakeup = int((wakeup - start) / duration * num_frames)\n",
    "        if onset >= 0 and onset < num_frames:\n",
    "            label[onset, 1] = 1\n",
    "        if wakeup < num_frames and wakeup >= 0:\n",
    "            label[wakeup, 2] = 1\n",
    "\n",
    "        onset = max(0, onset)\n",
    "        wakeup = min(num_frames, wakeup)\n",
    "        label[onset:wakeup, 0] = 1  # sleep\n",
    "\n",
    "    return label\n",
    "\n",
    "\n",
    "class SegTrainDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cfg: TrainConfig,\n",
    "        features: dict[str, np.ndarray],\n",
    "        event_df: pl.DataFrame,\n",
    "    ):\n",
    "        self.cfg = cfg\n",
    "        # only positive samples\n",
    "        self.event_df_pos: pd.DataFrame = (\n",
    "            event_df.pivot(index=[\"series_id\", \"night\"], columns=\"event\", values=\"step\")\n",
    "            .drop_nulls()\n",
    "            .to_pandas()\n",
    "        )\n",
    "        # all samples\n",
    "        self.event_df: pd.DataFrame = (\n",
    "            event_df.pivot(index=[\"series_id\", \"night\"], columns=\"event\", values=\"step\")\n",
    "            .to_pandas()\n",
    "        )\n",
    "        self.features = features\n",
    "        self.num_features = len(cfg.features)\n",
    "        self.upsampled_num_frames = nearest_valid_size(\n",
    "            int(self.cfg.duration * self.cfg.upsample_rate), self.cfg.downsample_rate\n",
    "        )\n",
    "        self.max_steps = {'05e1944c3818': 139992, '13b4d6a01d27': 92484, \n",
    "                          '7476c0bd18d2': 83988, '5aad18e7ce64': 18216,\n",
    "                          'aed3850f65f0': 21228, 'c5365a55ebb7': 17772, \n",
    "                          'f981a0805fd0': 75192}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.event_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        event = np.random.choice([\"onset\", \"wakeup\"], p=[0.5, 0.5])\n",
    "        pos = self.event_df.at[idx, event]\n",
    "        \n",
    "        positive = False if random.random() < self.cfg.dataset.bg_sampling_rate else True\n",
    "        if positive:\n",
    "            idx = idx % len(self.event_df_pos)    \n",
    "            series_id = self.event_df_pos.at[idx, \"series_id\"]\n",
    "            this_event_df = self.event_df_pos.query(\"series_id == @series_id\").reset_index(drop=True)\n",
    "        else:\n",
    "            series_id = self.event_df.at[idx, \"series_id\"]\n",
    "            this_event_df = self.event_df.query(\"series_id == @series_id\").reset_index(drop=True)\n",
    "        \n",
    "        # extract data matching series_id\n",
    "        this_feature = self.features[series_id]  # (n_steps, num_features)\n",
    "        n_steps = this_feature.shape[0]\n",
    "\n",
    "        # sample background\n",
    "        if positive:\n",
    "            max_step = self.max_steps[series_id] if series_id in self.max_steps else 1e9\n",
    "            pos = negative_sampling(this_event_df, n_steps, max_step, self.cfg.duration)\n",
    "\n",
    "        # crop\n",
    "        if n_steps > self.cfg.duration:\n",
    "            start, end = random_crop(pos, self.cfg.duration, n_steps)\n",
    "            feature = this_feature[start:end]\n",
    "        else:\n",
    "            start, end = 0, self.cfg.duration\n",
    "            feature = pad_if_needed(this_feature, self.cfg.duration)\n",
    "\n",
    "        # upsample\n",
    "        feature = torch.FloatTensor(feature.T).unsqueeze(0)  # (1, num_features, duration)\n",
    "        feature = resize(\n",
    "            feature,\n",
    "            size=[self.num_features, self.upsampled_num_frames],\n",
    "            antialias=False,\n",
    "        ).squeeze(0)\n",
    "\n",
    "        # from hard label to gaussian label\n",
    "        num_frames = self.upsampled_num_frames // self.cfg.downsample_rate\n",
    "        label = get_seg_label(this_event_df, num_frames, self.cfg.duration, start, end)\n",
    "        \n",
    "        # label[:, 0] = add_gaussian_sleep(label[:, 0], offset=self.cfg.dataset.offset)\n",
    "        label[:, [1, 2]] = gaussian_label(\n",
    "            label[:, [1, 2]], offset=self.cfg.dataset.offset, sigma=self.cfg.dataset.sigma\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"series_id\": series_id,\n",
    "            \"feature\": feature,  # (num_features, upsampled_num_frames)\n",
    "            \"label\": torch.FloatTensor(label),  # (pred_length, num_classes)\n",
    "        }\n",
    "\n",
    "\n",
    "class SegValidDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cfg: TrainConfig,\n",
    "        chunk_features: dict[str, np.ndarray],\n",
    "        event_df: pl.DataFrame,\n",
    "    ):\n",
    "        self.cfg = cfg\n",
    "        self.chunk_features = chunk_features\n",
    "        self.keys = list(chunk_features.keys())\n",
    "        self.event_df = (\n",
    "            event_df.pivot(index=[\"series_id\", \"night\"], columns=\"event\", values=\"step\")\n",
    "            .drop_nulls()\n",
    "            .to_pandas()\n",
    "        )\n",
    "        self.num_features = len(cfg.features)\n",
    "        self.upsampled_num_frames = nearest_valid_size(\n",
    "            int(self.cfg.duration * self.cfg.upsample_rate), self.cfg.downsample_rate\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        key = self.keys[idx]\n",
    "        feature = self.chunk_features[key]\n",
    "        feature = torch.FloatTensor(feature.T).unsqueeze(0)  # (1, num_features, duration)\n",
    "        feature = resize(\n",
    "            feature,\n",
    "            size=[self.num_features, self.upsampled_num_frames],\n",
    "            antialias=False,\n",
    "        ).squeeze(0)\n",
    "\n",
    "        series_id, chunk_id = key.split(\"_\")\n",
    "        chunk_id = int(chunk_id)\n",
    "        start = chunk_id * self.cfg.duration\n",
    "        end = start + self.cfg.duration\n",
    "        num_frames = self.upsampled_num_frames // self.cfg.downsample_rate\n",
    "        \n",
    "        label = get_seg_label(\n",
    "            self.event_df.query(\"series_id == @series_id\").reset_index(drop=True),\n",
    "            num_frames,\n",
    "            self.cfg.duration,\n",
    "            start,\n",
    "            end,\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"key\": key,\n",
    "            \"feature\": feature,  # (batch_size, num_features, duration)\n",
    "            \"label\": torch.FloatTensor(label),  # (batch_size, duration // 2, num_classes)\n",
    "        }\n",
    "\n",
    "\n",
    "class SegTestDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cfg: InferenceConfig,\n",
    "        chunk_features: dict[str, np.ndarray],\n",
    "    ):\n",
    "        self.cfg = cfg\n",
    "        self.chunk_features = chunk_features\n",
    "        self.keys = list(chunk_features.keys())\n",
    "        self.num_features = len(cfg.features)\n",
    "        self.upsampled_num_frames = nearest_valid_size(\n",
    "            int(self.cfg.duration * self.cfg.upsample_rate), self.cfg.downsample_rate\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        key = self.keys[idx]\n",
    "        feature = self.chunk_features[key]\n",
    "        feature = torch.FloatTensor(feature.T).unsqueeze(0)  # (1, num_features, duration)\n",
    "        feature = resize(\n",
    "            feature,\n",
    "            size=[self.num_features, self.upsampled_num_frames],\n",
    "            antialias=False,\n",
    "        ).squeeze(0)\n",
    "        \n",
    "        return {\n",
    "            \"key\": key,\n",
    "            \"feature\": feature,  # (num_features, duration)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas\n",
    "\n",
    "- check  with fixed sampling \n",
    "\n",
    "- try with full data\n",
    "- try with 6, 7, 8 folds\n",
    "\n",
    "- try again gaussian loss\n",
    "- fix DETR\n",
    "\n",
    "What works and gives boost but overfits:\n",
    "- LSTM encoder (0.772/~0.722)\n",
    "- resnet50 (0.780/0.722)\n",
    "- duration 17280 (0.772/0.722)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1800226/4092731947.py:40: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  initialize(config_path=config_path.as_posix())\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from hydra import initialize, compose\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from src.utils.metrics import event_detection_ap\n",
    "\n",
    "from src.utils.post_process import post_process_for_seg\n",
    "import jupyter_black\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import optuna\n",
    "\n",
    "\n",
    "jupyter_black.load()\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "INFERENCE = True\n",
    "EXP_NAME = \"transformer_dur_8640_folds\"\n",
    "RUN_NAME = \"run0\"\n",
    "TYPE = \"score\"\n",
    "\n",
    "if INFERENCE:\n",
    "    RESULT_DIR = Path(\"../output/inference\") / EXP_NAME  # / RUN_NAME\n",
    "    hydra_result_dir = Path(\"../output/train\") / \"transformer_dur_8640_folds\" / RUN_NAME\n",
    "else:\n",
    "    RESULT_DIR = Path(\"../output/train\") / EXP_NAME / RUN_NAME\n",
    "    hydra_result_dir = Path(\"../output/train\") / EXP_NAME / RUN_NAME\n",
    "\n",
    "\n",
    "def load_config(result_dir: Path):\n",
    "    # clear previous initialization\n",
    "    GlobalHydra.instance().clear()\n",
    "\n",
    "    # initialize hydra\n",
    "    config_path = result_dir / \".hydra\"\n",
    "    initialize(config_path=config_path.as_posix())\n",
    "    # load the config\n",
    "    cfg = compose(config_name=\"config\")\n",
    "\n",
    "    return cfg\n",
    "\n",
    "\n",
    "cfg = load_config(hydra_result_dir)\n",
    "\n",
    "if INFERENCE:\n",
    "    preds = np.load(RESULT_DIR / f\"preds.npy\")\n",
    "    keys = np.load(RESULT_DIR / f\"keys.npy\")\n",
    "else:\n",
    "    preds = np.load(RESULT_DIR / f\"preds_{TYPE}.npy\")\n",
    "    labels = np.load(RESULT_DIR / f\"labels_{TYPE}.npy\")\n",
    "    keys = np.load(RESULT_DIR / \"keys.npy\")\n",
    "\n",
    "gt_df = pd.read_csv(Path(cfg.dir.data_dir) / \"train_events.csv\")\n",
    "gt_df = gt_df[gt_df[\"series_id\"].isin(cfg.split.valid_series_ids)].dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize postprocess parameters using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7945928237902742, 352926)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(Path(cfg.dir.processed_dir) / \"train\" / \"series_lens.json\") as f:\n",
    "    series_lens = json.load(f)\n",
    "\n",
    "pred_df = post_process_for_seg(keys, preds, series_lens, score_th=0.0001, distance=70, offset=8)\n",
    "# pred_df = pred_df.to_pandas()\n",
    "\n",
    "score = event_detection_ap(gt_df, pred_df)\n",
    "\n",
    "score, len(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (0.7945928237902742, 352926)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold 5_0 - 0.765 / 0.733 - rank 1\n",
    "# fold 5_3 - 0.772 / 0.733 - rank 3\n",
    "\n",
    "# fold 10_2 - 0.0001 / 85 / 0.811 / 0.729 (0.709 for the best loss) - rank 6\n",
    "# fold 10_4 - 0.0001 / 70 / 0.789 / 0.734 - rank 2\n",
    "# fold 10_6 - 0.0001 / 70 / 0.779 / 0.733 - rank 4\n",
    "# fold 10_7 - 0.0001 / 80 / 0.792 / 0.729 - rank 5\n",
    "# fold 10_9 - 0.0001 / 80 / 0.812 / 0.722"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial):\n",
    "    # score_th = 0.005\n",
    "    score_th = trial.suggest_float(\"score_th\", 0, 0.5)\n",
    "    distance = trial.suggest_int(\"distance\", 30, 400)\n",
    "\n",
    "    pred_df: pl.DataFrame = post_process_for_seg(keys, preds, score_th=score_th, distance=distance)\n",
    "    score = event_detection_ap(gt_df, pred_df)\n",
    "\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_random_sample(gt_df, keys, preds, labels, num_samples=1, num_chunks=10):\n",
    "    # get series ids\n",
    "    series_ids = np.array(list(map(lambda x: x.split(\"_\")[0], keys)))\n",
    "    unique_series_ids = np.unique(series_ids)\n",
    "\n",
    "    # get random series\n",
    "    random_series_ids = np.random.choice(unique_series_ids, num_samples)\n",
    "\n",
    "    for i, random_series_id in enumerate(random_series_ids):\n",
    "        # get random series\n",
    "        series_idx = np.where(series_ids == random_series_id)[0]\n",
    "        this_series_preds = preds[series_idx].reshape(-1, 3)\n",
    "        this_series_labels = labels[series_idx].reshape(-1, 3)\n",
    "\n",
    "        # split series\n",
    "        this_series_preds = np.split(this_series_preds, num_chunks)\n",
    "        this_series_labels = np.split(this_series_labels, num_chunks)\n",
    "        this_series_len = [0] + [len(x) for x in this_series_labels]\n",
    "        this_series_len = np.cumsum(this_series_len)\n",
    "\n",
    "        gt_df = gt_df[gt_df[\"series_id\"] == random_series_id]\n",
    "\n",
    "        fig, axs = plt.subplots(num_chunks, 1, figsize=(20, 5 * num_chunks))\n",
    "\n",
    "        if num_chunks == 1:\n",
    "            axs = [axs]\n",
    "\n",
    "        for j in range(num_chunks):\n",
    "            this_series_preds_chunk = this_series_preds[j]\n",
    "            this_series_labels_chunk = this_series_labels[j]\n",
    "\n",
    "            # get onset and wakeup idx\n",
    "            gt_tmp = gt_df[\n",
    "                (gt_df[\"step\"] >= this_series_len[j]) & (gt_df[\"step\"] <= this_series_len[j + 1])\n",
    "            ]\n",
    "            onset_idx = gt_tmp.loc[gt_tmp[\"event\"] == \"onset\", \"step\"].to_list()\n",
    "            onset_idx = onset_idx - this_series_len[j]\n",
    "            wakeup_idx = gt_tmp.loc[gt_tmp[\"event\"] == \"wakeup\", \"step\"].to_list()\n",
    "            wakeup_idx = wakeup_idx - this_series_len[j]\n",
    "\n",
    "            axs[j].plot(this_series_preds_chunk[:, 0], label=\"pred_sleep\")\n",
    "            axs[j].plot(this_series_preds_chunk[:, 1], label=\"pred_onset\")\n",
    "            axs[j].plot(this_series_preds_chunk[:, 2], label=\"pred_wakeup\")\n",
    "            axs[j].vlines(onset_idx, 0, 1, label=\"onset\", linestyles=\"dashed\", color=\"C1\")\n",
    "            axs[j].vlines(wakeup_idx, 0, 1, label=\"wakeup\", linestyles=\"dashed\", color=\"C2\")\n",
    "            axs[j].set_ylim(0, 1)\n",
    "            axs[j].set_title(f\"series_id: {random_series_id} chunk_id: {j}\")\n",
    "            axs[j].legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\", borderaxespad=0)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "plot_random_sample(gt_df, keys, preds, labels, num_chunks=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "BEST_MODEL = \"ensemble\"\n",
    "FOLD = 0\n",
    "\n",
    "DURATION = 8640\n",
    "DOWNSAMPLE_RATE = 2\n",
    "PHASE = \"train\"\n",
    "EXP_NAME = \"transformer_best_folds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "[5.0GB(+3.9GB):2.2sec] load test dataloader \n",
      "List of models: ['/home/alex/Kaggle/DSS/output/train/transformer_best_folds/fold_0.pth', '/home/alex/Kaggle/DSS/output/train/transformer_best_folds/fold_10_2.pth', '/home/alex/Kaggle/DSS/output/train/transformer_best_folds/fold_10_4.pth', '/home/alex/Kaggle/DSS/output/train/transformer_best_folds/fold_3.pth']\n",
      "load weight from /home/alex/Kaggle/DSS/output/train/transformer_best_folds/fold_0.pth\n",
      "load weight from /home/alex/Kaggle/DSS/output/train/transformer_best_folds/fold_10_2.pth\n",
      "load weight from /home/alex/Kaggle/DSS/output/train/transformer_best_folds/fold_10_4.pth\n",
      "load weight from /home/alex/Kaggle/DSS/output/train/transformer_best_folds/fold_3.pth\n",
      "[5.7GB(+0.7GB):4.8sec] load model \n",
      "inference: 100%|████████████████████████████| 1867/1867 [02:38<00:00, 11.80it/s]\n",
      "[7.4GB(+1.7GB):177.8sec] inference \n",
      "inference: 100%|████████████████████████████| 1867/1867 [02:38<00:00, 11.77it/s]\n",
      "[7.4GB(+0.0GB):180.0sec] inference \n",
      "inference: 100%|████████████████████████████| 1867/1867 [02:36<00:00, 11.93it/s]\n",
      "[7.4GB(+0.0GB):176.6sec] inference \n",
      "inference: 100%|████████████████████████████| 1867/1867 [02:36<00:00, 11.89it/s]\n",
      "[7.4GB(+0.0GB):176.8sec] inference \n",
      "[7.4GB(+0.0GB):1.0sec] make submission \n"
     ]
    }
   ],
   "source": [
    "!python -m run.inference\\\n",
    "    dir=local\\\n",
    "    model.params.encoder_name=resnet34\\\n",
    "    model.params.encoder_weights=null\\\n",
    "    num_workers=12\\\n",
    "    exp_name=$EXP_NAME\\\n",
    "    weight.run_name=single\\\n",
    "    batch_size=8\\\n",
    "    duration=$DURATION\\\n",
    "    downsample_rate=$DOWNSAMPLE_RATE\\\n",
    "    pp.score_th=0.0015\\\n",
    "    pp.distance=70\\\n",
    "    phase=$PHASE\\\n",
    "    best_model=$BEST_MODEL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
